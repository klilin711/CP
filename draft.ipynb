{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\clean_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unexpected cases: 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair ID</th>\n",
       "      <th>Grammatical Sentence</th>\n",
       "      <th>Ungrammatical Sentence</th>\n",
       "      <th>Grammatical JSD</th>\n",
       "      <th>Ungrammatical JSD</th>\n",
       "      <th>Grammatical Perplexity</th>\n",
       "      <th>Ungrammatical Perplexity</th>\n",
       "      <th>Matches Expectation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Last night the old lady died in her sleep.</td>\n",
       "      <td>Last night the old lady die in her sleep.</td>\n",
       "      <td>0.397543</td>\n",
       "      <td>0.374149</td>\n",
       "      <td>38.774673</td>\n",
       "      <td>98.982780</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sandy filled a jar with cookies last night.</td>\n",
       "      <td>Sandy fill a jar with cookies last night.</td>\n",
       "      <td>0.400852</td>\n",
       "      <td>0.376231</td>\n",
       "      <td>240.454773</td>\n",
       "      <td>478.766113</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>John sang for the church choir yesterday.</td>\n",
       "      <td>John sing for the church choir yesterday.</td>\n",
       "      <td>0.333753</td>\n",
       "      <td>0.300420</td>\n",
       "      <td>283.251495</td>\n",
       "      <td>288.029816</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Janie slept with her teddy bear last night.</td>\n",
       "      <td>Janie sleeped with her teddy bear last night.</td>\n",
       "      <td>0.430241</td>\n",
       "      <td>0.411652</td>\n",
       "      <td>47.483559</td>\n",
       "      <td>69.506531</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Last night the books fell off the shelves.</td>\n",
       "      <td>Last night the books falled off the shelves.</td>\n",
       "      <td>0.388130</td>\n",
       "      <td>0.359499</td>\n",
       "      <td>56.166302</td>\n",
       "      <td>146.006012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>The students went to the movies.</td>\n",
       "      <td>The students to the movies went.</td>\n",
       "      <td>0.381220</td>\n",
       "      <td>0.361611</td>\n",
       "      <td>69.671387</td>\n",
       "      <td>457.836456</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>The children play with the dog.</td>\n",
       "      <td>The children with the dog play.</td>\n",
       "      <td>0.356222</td>\n",
       "      <td>0.355248</td>\n",
       "      <td>55.560009</td>\n",
       "      <td>336.007965</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>The student eats his meals quickly.</td>\n",
       "      <td>The student eats quickly his meals.</td>\n",
       "      <td>0.359900</td>\n",
       "      <td>0.347272</td>\n",
       "      <td>235.834320</td>\n",
       "      <td>908.318848</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Kevin usually rides his bicycle to work.</td>\n",
       "      <td>Kevin rides usually his bicycle to work.</td>\n",
       "      <td>0.381580</td>\n",
       "      <td>0.326178</td>\n",
       "      <td>54.441608</td>\n",
       "      <td>219.733307</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>My neighbor slowly enjoyed his dessert.</td>\n",
       "      <td>My neighbor enjoyed slowly his dessert.</td>\n",
       "      <td>0.394377</td>\n",
       "      <td>0.374688</td>\n",
       "      <td>801.215942</td>\n",
       "      <td>4501.764648</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pair ID                         Grammatical Sentence  \\\n",
       "0         1   Last night the old lady died in her sleep.   \n",
       "1         2  Sandy filled a jar with cookies last night.   \n",
       "2         3    John sang for the church choir yesterday.   \n",
       "3         4  Janie slept with her teddy bear last night.   \n",
       "4         5   Last night the books fell off the shelves.   \n",
       "..      ...                                          ...   \n",
       "92       93             The students went to the movies.   \n",
       "93       94              The children play with the dog.   \n",
       "95       96          The student eats his meals quickly.   \n",
       "96       97     Kevin usually rides his bicycle to work.   \n",
       "97       98      My neighbor slowly enjoyed his dessert.   \n",
       "\n",
       "                           Ungrammatical Sentence  Grammatical JSD  \\\n",
       "0       Last night the old lady die in her sleep.         0.397543   \n",
       "1       Sandy fill a jar with cookies last night.         0.400852   \n",
       "2       John sing for the church choir yesterday.         0.333753   \n",
       "3   Janie sleeped with her teddy bear last night.         0.430241   \n",
       "4    Last night the books falled off the shelves.         0.388130   \n",
       "..                                            ...              ...   \n",
       "92               The students to the movies went.         0.381220   \n",
       "93                The children with the dog play.         0.356222   \n",
       "95            The student eats quickly his meals.         0.359900   \n",
       "96       Kevin rides usually his bicycle to work.         0.381580   \n",
       "97        My neighbor enjoyed slowly his dessert.         0.394377   \n",
       "\n",
       "    Ungrammatical JSD  Grammatical Perplexity  Ungrammatical Perplexity  \\\n",
       "0            0.374149               38.774673                 98.982780   \n",
       "1            0.376231              240.454773                478.766113   \n",
       "2            0.300420              283.251495                288.029816   \n",
       "3            0.411652               47.483559                 69.506531   \n",
       "4            0.359499               56.166302                146.006012   \n",
       "..                ...                     ...                       ...   \n",
       "92           0.361611               69.671387                457.836456   \n",
       "93           0.355248               55.560009                336.007965   \n",
       "95           0.347272              235.834320                908.318848   \n",
       "96           0.326178               54.441608                219.733307   \n",
       "97           0.374688              801.215942               4501.764648   \n",
       "\n",
       "    Matches Expectation  \n",
       "0                 False  \n",
       "1                 False  \n",
       "2                 False  \n",
       "3                 False  \n",
       "4                 False  \n",
       "..                  ...  \n",
       "92                False  \n",
       "93                False  \n",
       "95                False  \n",
       "96                False  \n",
       "97                False  \n",
       "\n",
       "[69 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the dataset\n",
    "def load_dataset(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "dataset_path = \"Dekeyser_test_dataset.json\"\n",
    "dataset = load_dataset(dataset_path)\n",
    "\n",
    "# Load GPT-2 model and tokenizer\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.eval()\n",
    "\n",
    "# Function to compute the JSD between two probability distributions\n",
    "def compute_jsd(p1, p2):\n",
    "    p1 = np.asarray(p1)\n",
    "    p2 = np.asarray(p2)\n",
    "    m = 0.5 * (p1 + p2)\n",
    "    return 0.5 * (entropy(p1, m) + entropy(p2, m))\n",
    "\n",
    "# Function to compute token-level probabilities\n",
    "def compute_token_probabilities(model, tokenizer, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "    \n",
    "    token_probs = [probs[0, i].numpy() for i in range(len(input_ids[0]))]\n",
    "    return token_probs\n",
    "\n",
    "# Compute GPT-2's prior probability distribution using the dataset\n",
    "def compute_prior_distribution_from_dataset(model, tokenizer, dataset):\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    token_counts = np.zeros(vocab_size)\n",
    "\n",
    "    for item in dataset:\n",
    "        sentences = [\n",
    "            item[\"sentences\"][0][\"text\"],\n",
    "            item[\"sentences\"][1][\"text\"],\n",
    "        ]\n",
    "        for sentence in sentences:\n",
    "            inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "            input_ids = inputs[\"input_ids\"]\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "                logits = outputs.logits\n",
    "                probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            for i in range(len(input_ids[0])):\n",
    "                token_counts += probs[0, i].numpy()\n",
    "\n",
    "    return token_counts / np.sum(token_counts)\n",
    "\n",
    "prior_distribution = compute_prior_distribution_from_dataset(model, tokenizer, dataset)\n",
    "\n",
    "def compute_perplexity(model, tokenizer, sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        loss = model(input_ids, labels=input_ids).loss\n",
    "    return torch.exp(loss).item()\n",
    "\n",
    "results = []\n",
    "for item in dataset:\n",
    "    pair_id = item[\"pair_id\"]\n",
    "    grammatical_sentence = item[\"sentences\"][1][\"text\"]\n",
    "    ungrammatical_sentence = item[\"sentences\"][0][\"text\"]\n",
    "\n",
    "    grammatical_probs = compute_token_probabilities(model, tokenizer, grammatical_sentence)\n",
    "    ungrammatical_probs = compute_token_probabilities(model, tokenizer, ungrammatical_sentence)\n",
    "\n",
    "    grammatical_jsd = np.mean([\n",
    "        compute_jsd(gp, prior_distribution) for gp in grammatical_probs\n",
    "    ])\n",
    "    ungrammatical_jsd = np.mean([\n",
    "        compute_jsd(up, prior_distribution) for up in ungrammatical_probs\n",
    "    ])\n",
    "\n",
    "    grammatical_perplexity = compute_perplexity(model, tokenizer, grammatical_sentence)\n",
    "    ungrammatical_perplexity = compute_perplexity(model, tokenizer, ungrammatical_sentence)\n",
    "\n",
    "    results.append({\n",
    "        \"Pair ID\": pair_id,\n",
    "        \"Grammatical Sentence\": grammatical_sentence,\n",
    "        \"Ungrammatical Sentence\": ungrammatical_sentence,\n",
    "        \"Grammatical JSD\": grammatical_jsd,\n",
    "        \"Ungrammatical JSD\": ungrammatical_jsd,\n",
    "        \"Grammatical Perplexity\": grammatical_perplexity,\n",
    "        \"Ungrammatical Perplexity\": ungrammatical_perplexity,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df[\"Matches Expectation\"] = results_df[\"Grammatical JSD\"] < results_df[\"Ungrammatical JSD\"]\n",
    "\n",
    "unexpected_cases = results_df[~results_df[\"Matches Expectation\"]]\n",
    "print(f\"Number of unexpected cases: {len(unexpected_cases)}\")\n",
    "display(unexpected_cases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
